# -*- coding: utf-8 -*-
"""Notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SKmor8NUrl1Kejf_rwYRJLp2DuR11w79

# **Recommendation System - Dicoding | Assignment**

## **1. Import Library and Load Data**

Importing libraries from Google Colab and Importing data from [GitHub](https://github.com/danalvr/MLT-Assignment-Dicoding/tree/main/Recommendation%20System/data).
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline

url_credit = 'https://raw.githubusercontent.com/danalvr/MLT-Assignment-Dicoding/main/Recommendation%20System/data/tmdb_5000_credits.csv'
url_movie = 'https://raw.githubusercontent.com/danalvr/MLT-Assignment-Dicoding/main/Recommendation%20System/data/tmdb_5000_movies.csv'
url_ratings = 'https://raw.githubusercontent.com/danalvr/MLT-Assignment-Dicoding/main/Recommendation%20System/data/ratings_small.csv'

credit_df = pd.read_csv(url_credit)
movie_df = pd.read_csv(url_movie)
ratings_df = pd.read_csv(url_ratings)

credit_df.head()

movie_df.head()

ratings_df.head()

print('Total data credit: ', len(credit_df.movie_id.unique()))
print('Total data movie: ', len(movie_df.id.unique()))
print('Total data ratings: ', len(ratings_df))

"""## **2. Exploratory Data Analysis dan Data Preprocessing**

### 2.1 Variabel Description

Check the information for each variable in the dataset that will be used.
"""

credit_df.info()

movie_df.info()

ratings_df.info()

"""### 2.2 Univariate Analysis

#### 2.2.1 Categorical Features
"""

movie_df.describe().apply(lambda s: s.apply('{0:.2f}'.format))

movie_categorical_features = movie_df.select_dtypes(include='object').columns.to_list()
print(movie_categorical_features)

for col in movie_categorical_features:
  count = movie_df[col].value_counts()
  percent = 100*movie_df[col].value_counts(normalize=True)
  df = pd.DataFrame({'Total sample':count, 'percentation':percent.round(1)})
  print('Feature: ', col)
  print(df, '\n\n')

"""#### 2.2.2 Numerical Features"""

movie_numerical_features = movie_df.select_dtypes(exclude=['object']).columns.to_list()
print(movie_numerical_features)

movie_df.hist(bins=50, figsize=(20,15))
plt.show()

"""### 2.3 Merge Credit and Movie Dataset

Join credit and movie datasets with a foregin key in the form of movie_id
"""

credit_df.columns = ['id','tittle','cast','crew']
movie_all_df= movie_df.merge(credit_df,on='id')

print('Total Movies: ', len(movie_all_df))

movie_all_df.head()

"""## **3. Data Preparation**

### 3.1 Assessing Variable

Assessing the dataset that has been previously combined in the movie_all_df variable.
"""

movie_all_df.info()

movie_all_df.isnull().sum()

movie_all_df['homepage'] = movie_all_df['homepage'].fillna('')
movie_all_df['overview'] = movie_all_df['overview'].fillna('')
movie_all_df['release_date'] = movie_all_df['release_date'].fillna('')
movie_all_df['runtime'] = movie_all_df['runtime'].fillna(0)
movie_all_df['tagline'] = movie_all_df['tagline'].fillna('')

movie_all_df.isnull().sum()

null_overview_movies = movie_all_df[movie_all_df['overview'].isnull()]

print(null_overview_movies)

"""### 3.2 Demographic Filtering

Create a demographic dataset and create a formula to calculate the recommendation score for each film based on several parameters:
- v is the number of votes for the movie;
- m is the minimum votes required to be listed in the chart;
- R is the average rating of the movie; And
- C is the mean vote across the whole report
"""

C = movie_all_df['vote_average'].mean()
C

m = movie_all_df['vote_count'].quantile(0.9)
m

q_movies = movie_all_df.copy().loc[movie_all_df['vote_count'] >= m]
q_movies.shape

def weighted_rating(x, m=m, C=C):
    v = x['vote_count']
    R = x['vote_average']
    return (v/(v+m) * R) + (m/(m+v) * C)

q_movies['score'] = q_movies.apply(weighted_rating, axis=1)

q_movies = q_movies.sort_values('score', ascending=False)

q_movies[['title', 'vote_count', 'vote_average', 'score']].head(10)

pop= movie_all_df.sort_values('popularity', ascending=False)
plt.figure(figsize=(12,4))

plt.barh(pop['title'].head(6),pop['popularity'].head(6), align='center',
        color='blue')
plt.gca().invert_yaxis()
plt.xlabel("Popularity")
plt.title("Popular Movies")

"""## **4. Modeling**

Create a recommendation system to display film recommendations using Content-Based Filtering and Collaborative Filtering techniques.

### 4.1 Content-Based Filtering

Implementating Content-Based Filtering techniques.
"""

movie_all_df['overview'].head(5)

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(stop_words='english')

movie_all_df['overview'] = movie_all_df['overview'].fillna('')

tfidf_matrix = tfidf.fit_transform(movie_all_df['overview'])

tfidf_matrix.shape

from sklearn.metrics.pairwise import linear_kernel

cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)

indices = pd.Series(movie_all_df.index, index=movie_all_df['title']).drop_duplicates()

def get_recommendations(title, cosine_sim=cosine_sim):
    idx = indices[title]

    sim_scores = list(enumerate(cosine_sim[idx]))

    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    sim_scores = sim_scores[1:11]

    movie_indices = [i[0] for i in sim_scores]

    return movie_all_df['title'].iloc[movie_indices]

get_recommendations('The Dark Knight Rises')

get_recommendations('Avatar')

from ast import literal_eval

features = ['cast', 'crew', 'keywords', 'genres']
for feature in features:
    movie_all_df[feature] = movie_all_df[feature].apply(literal_eval)

def get_director(x):
    for i in x:
        if i['job'] == 'Director':
            return i['name']
    return np.nan

def get_list(x):
    if isinstance(x, list):
        names = [i['name'] for i in x]
        if len(names) > 3:
            names = names[:3]
        return names

    return []

movie_all_df['director'] = movie_all_df['crew'].apply(get_director)

features = ['cast', 'keywords', 'genres']
for feature in features:
    movie_all_df[feature] = movie_all_df[feature].apply(get_list)

movie_all_df[['title', 'cast', 'director', 'keywords', 'genres']].head(3)

def clean_data(x):
    if isinstance(x, list):
        return [str.lower(i.replace(" ", "")) for i in x]
    else:
        if isinstance(x, str):
            return str.lower(x.replace(" ", ""))
        else:
            return ''

features = ['cast', 'keywords', 'director', 'genres']

for feature in features:
    movie_all_df[feature] = movie_all_df[feature].apply(clean_data)

def create_soup(x):
    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])
movie_all_df['soup'] = movie_all_df.apply(create_soup, axis=1)

from sklearn.feature_extraction.text import CountVectorizer

count = CountVectorizer(stop_words='english')
count_matrix = count.fit_transform(movie_all_df['soup'])

from sklearn.metrics.pairwise import cosine_similarity

cosine_sim2 = cosine_similarity(count_matrix, count_matrix)

movie_all_df = movie_all_df.reset_index()
indices = pd.Series(movie_all_df.index, index=movie_all_df['title'])

get_recommendations('The Dark Knight Rises', cosine_sim2)

get_recommendations('Avatar', cosine_sim2)

"""### 4.2 Collaborative Filtering

Implementing of Collaborative Filtering techniques using TensorFlow.
"""

user_ids = ratings_df['userId'].unique().tolist()
print('list userId: ', user_ids)

user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userId : ', user_to_user_encoded)

user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userId: ', user_encoded_to_user)

movie_ids = ratings_df['movieId'].unique().tolist()

movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}

movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}

ratings_df['user'] = ratings_df['userId'].map(user_to_user_encoded)

ratings_df['movie'] = ratings_df['movieId'].map(movie_to_movie_encoded)

num_users = len(user_to_user_encoded)
print(num_users)

num_movie = len(movie_encoded_to_movie)
print(num_movie)

ratings_df['rating'] = ratings_df['rating'].values.astype(np.float32)

min_rating = min(ratings_df['rating'])

max_rating = max(ratings_df['rating'])

print('Number of User: {}, Number of Movie: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

ratings_df = ratings_df.sample(frac=1, random_state=42)
ratings_df

x = ratings_df[['user', 'movie']].values

y = ratings_df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

train_indices = int(0.8 * ratings_df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

class RecommenderNet(tf.keras.Model):

  def __init__(self, num_users, num_movie, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movie = num_movie
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.movie_embedding = layers.Embedding(
        num_movie,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movie_bias = layers.Embedding(num_movie, 1)

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    movie_vector = self.movie_embedding(inputs[:, 1])
    movie_bias = self.movie_bias(inputs[:, 1])

    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)

    x = dot_user_movie + user_bias + movie_bias

    return tf.nn.sigmoid(x)

model = RecommenderNet(num_users, num_movie, 50)

model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 10,
    validation_data = (x_val, y_val)
)

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

movie_new = q_movies

user_id = ratings_df.userId.sample(1).iloc[0]
movie_visited_by_user = ratings_df[ratings_df.userId == user_id]

movie_not_visited = movie_new[~movie_new['id'].isin(movie_visited_by_user.movieId.values)]['id']
movie_not_visited = list(
    set(movie_not_visited)
    .intersection(set(movie_to_movie_encoded.keys()))
)

movie_not_visited = [[movie_to_movie_encoded.get(x)] for x in movie_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_visited), movie_not_visited)
)

ratings = model.predict(user_movie_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movie_not_visited[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('movie with high ratings from user')
print('----' * 8)

top_movie_user = (
    movie_visited_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)

movie_df_rows = movie_new[movie_new['id'].isin(top_movie_user)]
for row in movie_df_rows.itertuples():
    print(row.title, ':', row.vote_average)

print('----' * 8)
print('Top 10 movie recommendation')
print('----' * 8)

recommended_movie = movie_new[movie_new['id'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.title, ':', row.vote_average)